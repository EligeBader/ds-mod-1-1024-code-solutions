# -*- coding: utf-8 -*-
"""nlp-project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1JVHHFC4vYUxl8s4AYB34eA4gozvZVpIk

# Library
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
!pip install nltk
import nltk
from nltk.tokenize import word_tokenize, sent_tokenize
from nltk.corpus import stopwords
from nltk.stem import PorterStemmer, WordNetLemmatizer
# %matplotlib inline
from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer

"""# Read File"""

spam_df = pd.read_csv('spam.csv', encoding='latin-1')
spam_df.head()

spam_df.drop(['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'], axis=1, inplace=True)
spam_df.head()

"""## Tokenize"""

nltk.download('punkt')
nltk.download('punkt_tab')

V2 = spam_df['v2']

tok_V2 = []
for i in V2:
  words = word_tokenize(V2)
  tok_V2.append(words)

spam_df['v2'] = tok_V2